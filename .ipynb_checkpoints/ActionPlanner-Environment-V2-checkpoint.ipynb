{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WATER\n",
      "{'TEMPERATURE': 'COLD'}\n",
      "------------------\n",
      "KETTLE\n",
      "{'PLUGGED': 'PLUGGED_IN'}\n",
      "ON-COUNTER\n",
      "------------------\n",
      "TAP\n",
      "{'OFFON': 'OFF'}\n",
      "------------------\n",
      "COUNTER\n",
      "{}\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nengo\n",
    "import nengo.spa as spa\n",
    "import world\n",
    "import kitchen\n",
    "import nodes\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "D = 256\n",
    "\n",
    "test_world = kitchen.get_kitchen()\n",
    "# test_world.do('KETTLE','UNPLUG_KETTLE')\n",
    "test_world.print_state()\n",
    "\n",
    "\n",
    "effects = ['WATER_IN_KETTLE', 'KETTLE_UNDER_TAP', 'WATER_BOILED', 'KETTLE_PLUGGED_IN', 'KETTLE_UNPLUGGED', 'KETTLE']\n",
    "actions = ['FILL_KETTLE_FROM_TAP', 'PUT_KETTLE_UNDER_TAP', 'BOIL_KETTLE', 'PLUG_IN_KETTLE','UNPLUG_KETTLE','KETTLE']\n",
    "precons = ['KETTLE_UNDER_TAP','KETTLE_UNPLUGGED','WATER_IN_KETTLE','HAS_CORD']\n",
    "\n",
    "switches = ['PLAN','EXECUTE','NULL','DONE']\n",
    "\n",
    "\n",
    "effect_vocab = spa.Vocabulary(D)\n",
    "action_vocab = spa.Vocabulary(D)\n",
    "precon_vocab = spa.Vocabulary(D)\n",
    "switch_vocab = spa.Vocabulary(D)\n",
    "count_vocab = spa.Vocabulary(D)\n",
    "\n",
    "for effect in effects:\n",
    "    effect_vocab.parse(effect)\n",
    "    \n",
    "for action in actions:\n",
    "    action_vocab.parse(action)\n",
    "\n",
    "for precon in precons:\n",
    "    precon_vocab.parse(precon)  \n",
    "\n",
    "for switch in switches:\n",
    "    switch_vocab.parse(switch)\n",
    "    \n",
    "\n",
    "\n",
    "action_vocab['INDEX'].make_unitary()\n",
    "\n",
    "count_vocab.add('ZERO', count_vocab.identity)\n",
    "count_vocab['ONE'].make_unitary()\n",
    "count_vocab.add('TWO', count_vocab['ONE']*count_vocab['ONE'])\n",
    "count_vocab.add('THREE', count_vocab['TWO']*count_vocab['ONE'])\n",
    "\n",
    "mapping = np.zeros((D, len(action_vocab.keys)))\n",
    "\n",
    "mapping[:,0] = switch_vocab['NULL'].v\n",
    "mapping[:,1] = switch_vocab['NULL'].v\n",
    "mapping[:,2] = switch_vocab['NULL'].v\n",
    "mapping[:,3] = switch_vocab['NULL'].v\n",
    "mapping[:,4] = switch_vocab['EXECUTE'].v\n",
    "mapping[:,5] = switch_vocab['NULL'].v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-keyword arg after keyword arg (<ipython-input-442-ed947c7a7d81>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-442-ed947c7a7d81>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    model.count = spa.Memory(dimensions=D, vocab=count_vocab, 0.3)\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-keyword arg after keyword arg\n"
     ]
    }
   ],
   "source": [
    "from nengo.networks import AssociativeMemory \n",
    "\n",
    "motor_sys = nodes.MotorSystem(action_vocab, test_world)\n",
    "vision_sys = nodes.VisualSystem(precon_vocab, test_world)\n",
    "\n",
    "with spa.SPA(label='Planner Test') as model:\n",
    "\n",
    "    # For managing control signals\n",
    "    model.ctrl = spa.Memory(dimensions=D, tau=0.05) \n",
    "    model.switch = spa.Memory(dimensions=D, vocab=switch_vocab, tau=0.02)\n",
    "    \n",
    "    model.goal_comp = spa.Compare(dimensions=D, vocab=effect_vocab)\n",
    "    model.goal_stat = spa.Memory(dimensions=D, vocab=switch_vocab, tau=0.05)\n",
    "    \n",
    "    model.count = spa.Memory(dimensions=D, vocab=count_vocab, tau=0.3)\n",
    "    model.inc = spa.Memory(dimensions=D, vocab=count_vocab, tau=0.3)\n",
    "    \n",
    "    # Main state representations    \n",
    "    model.m_goal = spa.Memory(dimensions=D, vocab=effect_vocab)\n",
    "    model.i_goal = spa.Memory(dimensions=D, vocab=effect_vocab, synapse=0.005, tau=0.05)\n",
    "    model.action = spa.Memory(dimensions=D, vocab=action_vocab, synapse=0.005, tau=0.05)\n",
    "    model.precon = spa.Memory(dimensions=D, vocab=precon_vocab, synapse=0.005, tau=0.05)\n",
    "\n",
    "    # Associative Memories \n",
    "    model.action_to_precon = spa.AssociativeMemory(input_vocab=action_vocab, output_vocab=precon_vocab, \n",
    "                                                   input_keys=actions[:4], output_keys=precons, wta_output=True)\n",
    "    \n",
    "    model.goal_to_action = spa.AssociativeMemory(input_vocab=effect_vocab, output_vocab=action_vocab, \n",
    "                                                 input_keys=effects, output_keys=actions, wta_output=True)\n",
    "    \n",
    "    model.action_to_effect = spa.AssociativeMemory(input_vocab=action_vocab, output_vocab=effect_vocab,\n",
    "                                                   input_keys=actions, output_keys=effects, wta_output=True)\n",
    "    \n",
    "    model.task_switch = AssociativeMemory(input_vectors=action_vocab.vectors, output_vectors=mapping.T)\n",
    "                                \n",
    "    # Stack implementation\n",
    "    model.push = spa.Memory(dimensions=D, vocab=action_vocab, synapse=0.005, tau=0.1)\n",
    "    model.stack = spa.Memory(dimensions=D, vocab=action_vocab, synapse=0.005, tau=0.5)\n",
    "    model.top = spa.Memory(dimensions=D, vocab=action_vocab, synapse=0.005, tau=0.03)\n",
    "    model.clean_action = spa.AssociativeMemory(action_vocab, threshold=0.15)\n",
    "    \n",
    "    bg_actions = spa.Actions(\n",
    "        'dot(ctrl, START)      -->  i_goal=m_goal, ctrl=PLAN',\n",
    "        'dot(ctrl, PLAN)       -->  ctrl=GET_ACTION',\n",
    "        'dot(ctrl, GET_ACTION) -->  goal_to_action=1.5*i_goal, ctrl=GET_PRECON',\n",
    "        'dot(ctrl, GET_PRECON) -->  action_to_precon=1.5*action, push=1.5*(stack*INDEX+action), ctrl=SET_GOAL',\n",
    "        'dot(ctrl, SET_GOAL)   -->  i_goal=precon, stack=push, ctrl=PLAN',\n",
    "        \n",
    "        'dot(switch, EXECUTE)  -->  ctrl=TOP_STACK, count=ONE',\n",
    "        'dot(ctrl, TOP_STACK)  -->  clean_action=stack, ctrl=POP_STACK',\n",
    "        'dot(ctrl, POP_STACK)  -->  push=(stack-top)*~INDEX, ctrl=SET_STACK',\n",
    "        'dot(ctrl, SET_STACK)  -->  stack=10*push, ctrl=INC',\n",
    "        'dot(ctrl, INC)        -->  count=inc*ONE, ctrl=TOP_STACK',\n",
    "        \n",
    "        'dot(count, TWO)       -->  ctrl=PLAN, i_goal=m_goal',\n",
    "        'dot(goal_stat, DONE)  -->  ctrl=STOP',\n",
    "        '0.35                  -->  ')\n",
    "\n",
    "    ct_actions = spa.Actions(\n",
    "        'action=goal_to_action',\n",
    "        'precon=action_to_precon',\n",
    "        'top=clean_action',\n",
    "        'action_to_effect=top',\n",
    "        'inc=count')\n",
    "    \n",
    "    model.bg = spa.BasalGanglia(bg_actions)\n",
    "    model.ct = spa.Cortical(ct_actions)\n",
    "    model.thal = spa.Thalamus(model.bg)\n",
    "\n",
    "    def set_goal(t):\n",
    "        if 0.05 < t < 0.1: return 'WATER_BOILED'\n",
    "        else: return '0'\n",
    "\n",
    "    def set_plan(t):\n",
    "        if 0.03 < t < 0.07: return 'START'\n",
    "        else: return '0'\n",
    "\n",
    "    model.start = spa.Input(m_goal=set_goal, ctrl=set_plan)\n",
    "\n",
    "    model.motor = nengo.Node(motor_sys, size_in=D, size_out=1)\n",
    "    model.sense = nengo.Node(vision_sys, size_in=D, size_out=1)\n",
    "\n",
    "    # Node Connections\n",
    "    nengo.Connection(model.precon.state.output, model.sense[:])\n",
    "    nengo.Connection(model.top.state.output, model.motor[:])\n",
    "    \n",
    "    nengo.Connection(model.sense, model.switch.state.input, transform=switch_vocab['EXECUTE'].v.reshape(D,1))\n",
    "    \n",
    "    # Compare and AssocMem Connections\n",
    "    nengo.Connection(model.action.state.output, model.task_switch.input)\n",
    "    nengo.Connection(model.task_switch.output, model.switch.state.input, transform=0.7)\n",
    "    \n",
    "    nengo.Connection(model.goal_comp.output, model.goal_stat.state.input, transform=switch_vocab['DONE'].v.reshape(D,1))\n",
    "    nengo.Connection(model.top.state.output, model.goal_comp.inputA)\n",
    "    nengo.Connection(model.action_to_effect.output, model.goal_comp.inputB)\n",
    "    \n",
    "    # Probes\n",
    "    goal_probe = nengo.Probe(model.i_goal.state.output, synapse=0.03)\n",
    "    mgoal_probe = nengo.Probe(model.m_goal.state.output, synapse=0.03)\n",
    "    plan_probe = nengo.Probe(model.ctrl.state.output, synapse=0.03)\n",
    "    action_probe = nengo.Probe(model.action.state.output, synapse=0.03)\n",
    "    precon_probe = nengo.Probe(model.precon.state.output, synapse=0.03)\n",
    "    top_probe = nengo.Probe(model.top.state.output, synapse=0.03)\n",
    "    stack_probe = nengo.Probe(model.stack.state.output, synapse=0.03)\n",
    "    push_probe = nengo.Probe(model.push.state.output, synapse=0.03)\n",
    "    motor_probe = nengo.Probe(model.motor)\n",
    "    sense_probe = nengo.Probe(model.sense)\n",
    "    inc_probe = nengo.Probe(model.inc.state.output, synapse=0.03)\n",
    "    counter_probe = nengo.Probe(model.count.state.output, synapse=0.03)\n",
    "    goal_to_act_probe = nengo.Probe(model.goal_to_action.output, synapse=0.03)\n",
    "    goal_stat_probe = nengo.Probe(model.goal_stat.state.output, synapse=0.03)\n",
    "    switch_probe = nengo.Probe(model.switch.state.output, synapse=0.03)\n",
    "\n",
    "sim = nengo.Simulator(model, seed=np.random.randint(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results_full(sim):\n",
    "    fig = plt.figure(figsize=(18,12))\n",
    "\n",
    "    p1 = fig.add_subplot(7,1,1)\n",
    "    p1.plot(sim.trange(), model.similarity(sim.data, goal_probe))\n",
    "    p1.legend(model.get_output_vocab('i_goal').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p1.set_ylabel('Goal')\n",
    "\n",
    "    p2 = fig.add_subplot(7,1,2)\n",
    "    p2.plot(sim.trange(), model.similarity(sim.data, plan_probe))\n",
    "    p2.legend(model.get_output_vocab('ctrl').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=9)\n",
    "    p2.set_ylabel('Control Signal')\n",
    "\n",
    "    p3 = fig.add_subplot(7,1,3)\n",
    "    p3.plot(sim.trange(), model.similarity(sim.data, action_probe))\n",
    "    p3.legend(model.get_output_vocab('action').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p3.set_ylabel('Action')\n",
    "\n",
    "    p4 = fig.add_subplot(7,1,4)\n",
    "    p4.plot(sim.trange(), model.similarity(sim.data, precon_probe))\n",
    "    p4.legend(model.get_output_vocab('precon').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p4.set_ylabel('Precondition')\n",
    "\n",
    "    p5 = fig.add_subplot(7,1,5)\n",
    "    p5.plot(sim.trange(), model.similarity(sim.data, push_probe))\n",
    "    p5.legend(model.get_output_vocab('push').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p5.set_ylabel('Push')\n",
    "\n",
    "    p6 = fig.add_subplot(7,1,6)\n",
    "    p6.plot(sim.trange(), model.similarity(sim.data, stack_probe))\n",
    "    p6.legend(model.get_output_vocab('stack').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p6.set_ylabel('Stack')\n",
    "\n",
    "    p7 = fig.add_subplot(7,1,7)\n",
    "    p7.plot(sim.trange(), model.similarity(sim.data, top_probe))\n",
    "    p7.legend(model.get_output_vocab('top').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p7.set_ylabel('Popped')\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.75)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_additional(sim):\n",
    "    fig = plt.figure(figsize=(18,12))\n",
    "\n",
    "    p1 = fig.add_subplot(7,1,1)\n",
    "    p1.plot(sim.trange(), model.similarity(sim.data, goal_stat_probe))\n",
    "    p1.legend(model.get_output_vocab('goal_stat').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p1.set_ylabel('Goal Status')\n",
    "\n",
    "    p2 = fig.add_subplot(7,1,2)\n",
    "    p2.plot(sim.trange(), model.similarity(sim.data, mgoal_probe))\n",
    "    p2.legend(model.get_output_vocab('m_goal').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p2.set_ylabel('Main Goal')\n",
    "    \n",
    "    p3 = fig.add_subplot(7,1,3)\n",
    "    p3.plot(sim.trange(), sim.data[sense_probe])\n",
    "    p3.set_ylabel('Sensory Feedback')\n",
    "\n",
    "    p4 = fig.add_subplot(7,1,4)\n",
    "    p4.plot(sim.trange(), sim.data[motor_probe])\n",
    "    p4.set_ylabel('Motor Execution')\n",
    "\n",
    "    p5 = fig.add_subplot(7,1,5)\n",
    "    p5.plot(sim.trange(), model.similarity(sim.data, counter_probe))\n",
    "    p5.legend(model.get_output_vocab('count').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p5.set_ylabel('Counter')\n",
    "    \n",
    "    p6 = fig.add_subplot(7,1,6)\n",
    "    p6.plot(sim.trange(), model.similarity(sim.data, inc_probe))\n",
    "    p6.legend(model.get_output_vocab('inc').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p6.set_ylabel('Increment')\n",
    "    \n",
    "    p7 = fig.add_subplot(7,1,7)\n",
    "    p7.plot(sim.trange(), model.similarity(sim.data, switch_probe))\n",
    "    p7.legend(model.get_output_vocab('switch').keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "    p7.set_ylabel('Switch')\n",
    "\n",
    "    fig.subplots_adjust(hspace=1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim.reset()\n",
    "sim.run(1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results_full(sim)\n",
    "test_world.print_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_additional(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test if model's stack can be used symbolically (i.e. whether failure is in popping stage)\n",
    "def get_key(vocab, pointer, threshold):\n",
    "    key = None\n",
    "    similarities = vocab.dot(pointer)\n",
    "    ind = np.argmax(similarities)\n",
    "    print similarities[ind]\n",
    "    if similarities[ind] >= threshold:\n",
    "        key = vocab.keys[ind]\n",
    "    return key\n",
    "\n",
    "stack = sim.data[stack_probe][600]\n",
    "top = get_key(action_vocab, stack, 0.3)\n",
    "print top\n",
    "\n",
    "stack = spa.pointer.SemanticPointer(stack - action_vocab[top].v) * ~action_vocab['INDEX']\n",
    "top = get_key(action_vocab, stack, 0.3)\n",
    "print top\n",
    "\n",
    "stack = spa.pointer.SemanticPointer(stack.v - action_vocab[top].v) * ~action_vocab['INDEX']\n",
    "top = get_key(action_vocab, stack, 0.3)\n",
    "print top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
